{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:31.645327Z",
     "start_time": "2019-03-04T10:56:31.417502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/user/git/datasci\")\n",
    "from plots import *\n",
    "import sci.features as scif\n",
    "import sci.learn as scil\n",
    "import sci.plots as scip\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '{:.4f}'.format(x)) #Limiting floats output to\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:31.744670Z",
     "start_time": "2019-03-04T10:56:31.648305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "(891, 11)\n",
      "(891, 10)\n",
      "(418, 10)\n"
     ]
    }
   ],
   "source": [
    "# raw data\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_test = pd.read_csv('input/test.csv')\n",
    "\n",
    "df_train = df_train.set_index(\"PassengerId\")\n",
    "df_test = df_test.set_index(\"PassengerId\")\n",
    "\n",
    "y = df_train[\"Survived\"]\n",
    "X = df_train.drop('Survived', axis=1)\n",
    "\n",
    "print(y.shape)\n",
    "print(df_train.shape)\n",
    "print(X.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:31.803838Z",
     "start_time": "2019-03-04T10:56:31.746172Z"
    }
   },
   "outputs": [],
   "source": [
    "scif.normalize_feature_names(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop outliers from train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual outlier handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic outlier handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:31.950570Z",
     "start_time": "2019-03-04T10:56:31.805620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>types</th>\n",
       "      <th>n_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [types, n_types]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>types</th>\n",
       "      <th>n_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [types, n_types]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# columsn with more than one data type (excluding NaN values)\n",
    "display(scif.types_of_df(df_train, more_than_one=True))\n",
    "display(scif.types_of_df(df_test, more_than_one=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "- drop columns with mostly missing values: these might have very little value for generalization\n",
    "- columns with few missing values: we can drop the samples, or impute them. Dropping is only possible for the train_set, we can't drop from the live scoring set\n",
    "- we can drop samples with missing values, but that isn't a good option when we don't have many samples, plus they can be special cases which we do want to model\n",
    "- we can impute (fill) missing values, this makes sense sometimes, but not always as sometimes:\n",
    "- missing values can represent a special \"state\", like value is missing since for this sample it's irrelevant. Filling this value would be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:32.122295Z",
     "start_time": "2019-03-04T10:56:31.952147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>missing</th>\n",
       "      <th>percent</th>\n",
       "      <th>dtype</th>\n",
       "      <th>types</th>\n",
       "      <th>uniq</th>\n",
       "      <th>miss-idx</th>\n",
       "      <th>values</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>204</td>\n",
       "      <td>687</td>\n",
       "      <td>77.1044</td>\n",
       "      <td>object</td>\n",
       "      <td>str</td>\n",
       "      <td>147</td>\n",
       "      <td>1, 3, 5</td>\n",
       "      <td>A10, A14, A16, A19, A20, A23, A24, A26, ...</td>\n",
       "      <td>'B96 B98':4, 'C23 C25 C27':4, 'G6':4, 'D':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714</td>\n",
       "      <td>177</td>\n",
       "      <td>19.8653</td>\n",
       "      <td>float64</td>\n",
       "      <td>float</td>\n",
       "      <td>88</td>\n",
       "      <td>6, 18, 20</td>\n",
       "      <td>0.42, 0.67, 0.75, 0.83, 0.92, 1.0, 2.0, ...</td>\n",
       "      <td>'24.0':30, '22.0':27, '18.0':26, '19.0':25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>889</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>object</td>\n",
       "      <td>str</td>\n",
       "      <td>3</td>\n",
       "      <td>62, 830</td>\n",
       "      <td>C, Q, S</td>\n",
       "      <td>'S':644, 'C':168, 'Q':77...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count  missing  percent    dtype  types  uniq   miss-idx  \\\n",
       "Cabin       204      687  77.1044   object    str   147    1, 3, 5   \n",
       "Age         714      177  19.8653  float64  float    88  6, 18, 20   \n",
       "Embarked    889        2   0.2245   object    str     3    62, 830   \n",
       "\n",
       "                                               values  \\\n",
       "Cabin     A10, A14, A16, A19, A20, A23, A24, A26, ...   \n",
       "Age       0.42, 0.67, 0.75, 0.83, 0.92, 1.0, 2.0, ...   \n",
       "Embarked                                      C, Q, S   \n",
       "\n",
       "                                                   freq  \n",
       "Cabin     'B96 B98':4, 'C23 C25 C27':4, 'G6':4, 'D':...  \n",
       "Age       '24.0':30, '22.0':27, '18.0':26, '19.0':25...  \n",
       "Embarked                    'S':644, 'C':168, 'Q':77...  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scif.df_summary(df_train, missing_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:32.264377Z",
     "start_time": "2019-03-04T10:56:32.123689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>missing</th>\n",
       "      <th>percent</th>\n",
       "      <th>dtype</th>\n",
       "      <th>types</th>\n",
       "      <th>uniq</th>\n",
       "      <th>miss-idx</th>\n",
       "      <th>values</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>91</td>\n",
       "      <td>327</td>\n",
       "      <td>78.2297</td>\n",
       "      <td>object</td>\n",
       "      <td>str</td>\n",
       "      <td>76</td>\n",
       "      <td>892, 893, 894</td>\n",
       "      <td>A11, A18, A21, A29, A34, A9, B10, B11, ...</td>\n",
       "      <td>'B57 B59 B63 B66':3, 'C55 C57':2, 'C101':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>332</td>\n",
       "      <td>86</td>\n",
       "      <td>20.5742</td>\n",
       "      <td>float64</td>\n",
       "      <td>float</td>\n",
       "      <td>79</td>\n",
       "      <td>902, 914, 921</td>\n",
       "      <td>0.17, 0.33, 0.75, 0.83, 0.92, 1.0, 2.0, ...</td>\n",
       "      <td>'24.0':17, '21.0':17, '22.0':16, '30.0':15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2392</td>\n",
       "      <td>float64</td>\n",
       "      <td>float</td>\n",
       "      <td>169</td>\n",
       "      <td>1044</td>\n",
       "      <td>0.0, 3.1708, 6.4375, 6.4958, 6.95, 7.0, ...</td>\n",
       "      <td>'7.75':21, '26.0':19, '8.05':17, '13.0':17...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  missing  percent    dtype  types  uniq       miss-idx  \\\n",
       "Cabin     91      327  78.2297   object    str    76  892, 893, 894   \n",
       "Age      332       86  20.5742  float64  float    79  902, 914, 921   \n",
       "Fare     417        1   0.2392  float64  float   169           1044   \n",
       "\n",
       "                                            values  \\\n",
       "Cabin   A11, A18, A21, A29, A34, A9, B10, B11, ...   \n",
       "Age    0.17, 0.33, 0.75, 0.83, 0.92, 1.0, 2.0, ...   \n",
       "Fare   0.0, 3.1708, 6.4375, 6.4958, 6.95, 7.0, ...   \n",
       "\n",
       "                                                freq  \n",
       "Cabin   'B57 B59 B63 B66':3, 'C55 C57':2, 'C101':...  \n",
       "Age    '24.0':17, '21.0':17, '22.0':16, '30.0':15...  \n",
       "Fare   '7.75':21, '26.0':19, '8.05':17, '13.0':17...  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scif.df_summary(df_test, missing_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:32.320345Z",
     "start_time": "2019-03-04T10:56:32.267775Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df_train\n",
    "# sizes = df.groupby(\"Ticket\").size()\n",
    "# df_merge = df.merge(sizes.rename(\"group_size\"), left_on=\"Ticket\", right_index=True, how=\"outer\", suffixes=('', ''))\n",
    "# df_merge = df_merge.sort_index()\n",
    "# scif.df_comp(df, df_merge.drop(\"group_size\", axis=1), \"orig\", \"merge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:32.382081Z",
     "start_time": "2019-03-04T10:56:32.323485Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_deck(cabin):\n",
    "    if pd.isnull(cabin):\n",
    "        return \"None\"\n",
    "    return cabin.split(\" \")[-1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T12:38:59.011789Z",
     "start_time": "2019-03-04T12:38:58.696513Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    df = df.copy()\n",
    "    df = df.merge(df.groupby(\"Ticket\").size().rename(\"group_size\"), left_on=\"Ticket\", right_index=True, how=\"outer\", suffixes=('', ''))\n",
    "    df = df.sort_index()\n",
    "    df = df.merge(df.groupby(\"Cabin\").size().rename(\"group_size2\"), left_on=\"Cabin\", right_index=True, how=\"outer\", suffixes=('', ''))\n",
    "    df = df.sort_index()\n",
    "    # fill with 0, as people with no Cabin are logically in a group of size 0 for Cabins\n",
    "    df[\"group_size2\"] = df[\"group_size2\"].fillna(0)\n",
    "    df.drop(\"Ticket\", axis=1, inplace=True)\n",
    "    \n",
    "    df[\"family_size\"] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "    df[\"has_cabin\"] = df.Cabin.notnull()\n",
    "    df[\"deck\"] = df.Cabin.apply(get_deck)\n",
    "    # TBD: CABIN WORK\n",
    "    df.drop(\"Cabin\", axis=1, inplace=True)\n",
    "\n",
    "    df[\"has_age\"] = df.Age.notnull()\n",
    "\n",
    "    df[\"Title\"] = df.Name.apply(lambda x: x.split(\", \")[1].split(\" \")[0])\n",
    "    df.loc[~df[\"Title\"].isin(['Mr.', 'Miss.', 'Mrs.', 'Master.']), \"Title\"] = \"Other.\"\n",
    "#     df[\"FamilyName\"] = df.Name.apply(lambda x: x.split(\", \")[0])\n",
    "#     df[\"FirstName\"] = df.Name.apply(lambda x: \" \".join(x.split(\", \")[1].split(\" \")[1:]))\n",
    "    df[\"Name_has_paren\"] = df.Name.str.contains('(', regex=False)\n",
    "    df[\"Name_has_quote\"] = df.Name.str.contains('\"', regex=False)\n",
    "    df.drop(\"Name\", axis=1, inplace=True)\n",
    "\n",
    "    # Fare == 0 looks like a mistake in the data\n",
    "    df.loc[df[\"Fare\"] == 0, \"Fare\"] = np.nan\n",
    "    # we add has_fare and them fill with MICE\n",
    "    df[\"has_fare\"] = df[\"Fare\"].notnull()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_proc = process(df_train)\n",
    "df_test_proc = process(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T12:41:06.757807Z",
     "start_time": "2019-03-04T12:41:06.689454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master.</th>\n",
       "      <td>nan</td>\n",
       "      <td>40.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss.</th>\n",
       "      <td>182.0000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr.</th>\n",
       "      <td>nan</td>\n",
       "      <td>517.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs.</th>\n",
       "      <td>125.0000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other.</th>\n",
       "      <td>7.0000</td>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female     male\n",
       "Title                    \n",
       "Master.      nan  40.0000\n",
       "Miss.   182.0000      nan\n",
       "Mr.          nan 517.0000\n",
       "Mrs.    125.0000      nan\n",
       "Other.    7.0000  20.0000"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_proc.pivot_table(index=\"Title\", columns=\"Sex\", aggfunc=\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:57:04.215370Z",
     "start_time": "2019-03-04T10:57:04.138676Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_proc, df_test_proc = scif.get_dummies(df_train_proc, df_test_proc, target=\"Survived\", dummy_na=False, drop_first=False, reintroduce_na=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:57:04.589319Z",
     "start_time": "2019-03-04T10:57:04.443898Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-618f01795237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_proc_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute_iterative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Embarked\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_train_proc_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train_proc_imp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m# we assume baby if imputed age was below zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test_proc_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute_iterative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Embarked\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_test_proc_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test_proc_imp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m# we assume baby if imputed age was below zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/datasci/sci/features.py\u001b[0m in \u001b[0;36mimpute_iterative\u001b[0;34m(df, columns, one_hot_columns)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mone_hot_c\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mone_hot_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/datasci/sci/features.py\u001b[0m in \u001b[0;36msoftmax_apply\u001b[0;34m(df, cols)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0margmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test2/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \"\"\"\n\u001b[0;32m-> 1037\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test2/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "df_train_proc_imp = scif.impute_iterative(df_train_proc, one_hot_columns=[\"Embarked\", \"Sex\"])\n",
    "df_train_proc_imp.loc[df_train_proc_imp[\"Age\"]<0, \"Age\"]= 0.1 # we assume baby if imputed age was below zero\n",
    "\n",
    "df_test_proc_imp = scif.impute_iterative(df_test_proc, one_hot_columns=[\"Embarked\", \"Sex\"])\n",
    "df_test_proc_imp.loc[df_test_proc_imp[\"Age\"]<0, \"Age\"]= 0.1 # we assume baby if imputed age was below zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.616741Z",
     "start_time": "2019-03-04T10:56:33.447858Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Title'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-eb63c025b1fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf_train_proc_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_proc_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdf_test_proc_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_proc_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf_train_proc_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_proc_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_proc_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_proc_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreintroduce_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-278-eb63c025b1fc>\u001b[0m in \u001b[0;36mprocess2\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     df[\"fare_q\"] = df[\"fare_q\"].astype(str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test2/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test2/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test2/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test2/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Title'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def process2(df):\n",
    "    df[\"age_group\"] = pd.cut(df[\"Age\"], [0, 2, 6, 12, 18, 25, 35, 45, 120])\n",
    "    df[\"age_group\"] = df[\"age_group\"].astype(str)\n",
    "    \n",
    "    # div by group_size as all Fare is for all people with the same ticket\n",
    "    df[\"fare_norm\"] = df[\"Fare\"] / df[\"group_size\"]\n",
    "#     df[\"fare_q\"] = pd.qcut(df[\"fare_norm\"], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])    \n",
    "#     df[\"fare_q\"] = df[\"fare_q\"].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_proc_imp = process2(df_train_proc_imp)\n",
    "df_test_proc_imp = process2(df_test_proc_imp)\n",
    "df_train_proc_imp, df_test_proc_imp = scif.get_dummies(df_train_proc_imp, df_test_proc_imp, target=\"Survived\", dummy_na=False, drop_first=False, reintroduce_na=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding string features:\n",
    "- opt-1: pd.factorize() and sklearn.LabelEncoder(): convert a single string feature to a single int features by mapping each label value to a number (and remember the mapping for later use)\n",
    "- opt-2: pd.get_dummies() and sklearn.OneHotEncoder(): convert a single string feature to many bool features, 1-per label value\n",
    "- note: get_dummies also supports drop_first which helps reduce dimensions and colinearity\n",
    "but to be 100% sure we don't have different dummies between what the model expects (train) and test, we should use OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch all to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.619907Z",
     "start_time": "2019-03-04T10:56:31.378Z"
    }
   },
   "outputs": [],
   "source": [
    "scif.assert_no_missing_values(df_train_proc_imp)\n",
    "scif.assert_no_missing_values(df_test_proc_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check and reduce skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.621656Z",
     "start_time": "2019-03-04T10:56:31.380Z"
    }
   },
   "outputs": [],
   "source": [
    "# scif.skewness_check(df_train_proc_imp).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.623219Z",
     "start_time": "2019-03-04T10:56:31.382Z"
    }
   },
   "outputs": [],
   "source": [
    "# scif.skewness_fix(df_train_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features\n",
    "- text features with few values are classic categorical features\n",
    "- text features with rich content are NOT\n",
    "- numeric (integer) features with few values that represent categories can be treated as categorical, but can also be processed as numeric and let the model figure it out\n",
    "\n",
    "What do we do with them?\n",
    "- we can convert them to integers using LabelEncoder and let the model figure it out\n",
    "- we can convert them to one-hot features using get_dummie or OneHotEncoder\n",
    "\n",
    "TODO:  \n",
    "solved with (drop_first=True) ?  \n",
    "https://www.algosome.com/articles/dummy-variable-trap-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.625147Z",
     "start_time": "2019-03-04T10:56:31.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import *\n",
    "\n",
    "# X = df_train_proc_imp\n",
    "# # X = df_train_proc_imp.drop('Survived', axis=1)\n",
    "# y = df_train['Survived']\n",
    "# model = RidgeCV()\n",
    "# model.fit(X, y)\n",
    "# # from sklearn.model_selection import cross_val_score\n",
    "# # cross_val_score(model, X, y, scoring=rmse_score).mean()\n",
    "\n",
    "# y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "# y_resid = y - y_pred\n",
    "# resid_mean = y_resid.mean()\n",
    "# resid_std  = y_resid.std()\n",
    "# resid_z = (y_resid - resid_mean) / resid_std\n",
    "# outliers_idx = y.index[np.abs(resid_z) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.627217Z",
     "start_time": "2019-03-04T10:56:31.386Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.scatter(y, y_pred)\n",
    "# plt.scatter(y.loc[outliers_idx], y_pred.loc[outliers_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.628917Z",
     "start_time": "2019-03-04T10:56:31.388Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train_proc = df_train_proc.drop(outliers_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.630145Z",
     "start_time": "2019-03-04T10:56:31.390Z"
    }
   },
   "outputs": [],
   "source": [
    "scif.normalize_feature_names(df_train_proc_imp, df_test_proc_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.631483Z",
     "start_time": "2019-03-04T10:56:31.393Z"
    }
   },
   "outputs": [],
   "source": [
    "scif.df_comp(df_train_proc_imp, df_test_proc_imp, \"train\", \"test\")\n",
    "# scif.df_comp(df_train_proc.drop([\"SalePrice\"], axis=1), df_test_proc, \"train\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:57:40.321678Z",
     "start_time": "2019-03-04T10:57:40.263836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 5) (891,) (418, 5)\n"
     ]
    }
   ],
   "source": [
    "# X_train = df_train_proc.set_index(\"Id\")\n",
    "y = df_train['Survived']\n",
    "X_train = df_train_proc_imp\n",
    "X_score = df_test_proc_imp\n",
    "\n",
    "print(X_train.shape, y.shape, X_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:57:44.102546Z",
     "start_time": "2019-03-04T10:57:43.894037Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'processed_my_'\n",
    "!mkdir -p $path\n",
    "X_train.to_msgpack(f'{path}/X.msgpack')\n",
    "y.to_msgpack(f'{path}/y.msgpack')\n",
    "X_score.to_msgpack(f'{path}/X_score.msgpack')\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(y_tr, f'{path}/y_tr.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:56:33.637739Z",
     "start_time": "2019-03-04T10:56:31.399Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.utils\n",
    "from sklearn.linear_model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:58:04.504656Z",
     "start_time": "2019-03-04T10:58:01.987501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 5) (891,)\n",
      "CV for XGBClassifier ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.785699 +/- 0.0160 SEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  10 out of  10 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "# model = ElasticNetCV(l1_ratio=0.5)\n",
    "model = xgboost.XGBClassifier()\n",
    "# model = SVC(kernel=\"linear\", C=0.025, probability=True)\n",
    "\n",
    "# sci.metric_global = roc_auc_score\n",
    "scil.scoring_global = 'accuracy'\n",
    "\n",
    "# path = 'processed_my'\n",
    "\n",
    "data = scil.load_data(path)\n",
    "cv_scores = scil.score_cv(data, model, scoring=scil.scoring_global, verbose=2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
